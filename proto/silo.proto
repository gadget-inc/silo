syntax = "proto3";

package silo.v1;

// Container for arbitrary serialized data with support for multiple encoding formats.
// Currently only MessagePack is supported, but structured as a union for forward compatibility
// to add new serialization formats in the future (e.g., JSON, Protobuf).
// Used for job payloads, results, error data, and query response rows.
message SerializedBytes {
  oneof encoding {
    bytes msgpack = 1; // Raw MessagePack bytes. Callers should serialize/deserialize using MessagePack.
  }
}

// Configuration for automatic job retry on failure.
// When a job attempt fails, Silo will automatically retry according to this policy.
message RetryPolicy {
  uint32 retry_count = 1;          // Maximum number of retry attempts after the initial attempt fails.
  int64 initial_interval_ms = 2;   // Initial delay in milliseconds before the first retry.
  int64 max_interval_ms = 3;       // Maximum delay between retries (caps exponential backoff).
  bool randomize_interval = 4;     // If true, adds jitter to retry intervals to prevent thundering herd.
  double backoff_factor = 5;       // Multiplier for exponential backoff (e.g., 2.0 doubles delay each retry).
}

// Static concurrency limit that restricts how many jobs with the same key can run simultaneously.
// Jobs sharing the same key will queue up if max_concurrency is reached.
message ConcurrencyLimit {
  string key = 1;             // Grouping key - jobs with the same key share this limit.
  uint32 max_concurrency = 2; // Maximum number of jobs with this key that can run at once.
}

// Dynamic concurrency limit where the max_concurrency value is computed by workers.
// Useful when concurrency should be based on external factors like API rate limits.
// Workers periodically receive refresh tasks to update the limit.
message FloatingConcurrencyLimit {
  string key = 1;                     // Grouping key - jobs with the same key share this limit.
  uint32 default_max_concurrency = 2; // Initial max concurrency used until first worker refresh.
  int64 refresh_interval_ms = 3;      // How often workers receive refresh tasks (milliseconds).
  map<string, string> metadata = 4;   // Arbitrary data passed to workers during refresh (e.g., API credentials).
}

// Rate limiting algorithm for Gubernator-based limits.
enum GubernatorAlgorithm {
  GUBERNATOR_ALGORITHM_TOKEN_BUCKET = 0; // Token bucket: tokens refill at steady rate, requests consume tokens.
  GUBERNATOR_ALGORITHM_LEAKY_BUCKET = 1; // Leaky bucket: requests processed at fixed rate, excess queued.
}

// Behavior flags for Gubernator rate limits. Can be combined via bitwise OR.
enum GubernatorBehavior {
  GUBERNATOR_BEHAVIOR_BATCHING = 0;           // Default: batch rate limit checks to peers for efficiency.
  GUBERNATOR_BEHAVIOR_NO_BATCHING = 1;        // Send each rate limit check immediately (lower latency, higher load).
  GUBERNATOR_BEHAVIOR_GLOBAL = 2;             // Synchronize rate limit globally across all Gubernator peers.
  GUBERNATOR_BEHAVIOR_DURATION_IS_GREGORIAN = 4; // Reset duration on calendar boundaries (minute, hour, day).
  GUBERNATOR_BEHAVIOR_RESET_REMAINING = 8;    // Force reset the remaining counter on this request.
  GUBERNATOR_BEHAVIOR_DRAIN_OVER_LIMIT = 16;  // Set remaining to zero on first over-limit event.
}

// Retry policy for when a job is blocked by a rate limit.
// Configures how long workers should wait before retrying the rate limit check.
message RateLimitRetryPolicy {
  int64 initial_backoff_ms = 1;  // Initial wait time in milliseconds when rate limited.
  int64 max_backoff_ms = 2;      // Maximum wait time between retries.
  double backoff_multiplier = 3; // Multiplier for exponential backoff (default 2.0).
  uint32 max_retries = 4;        // Max retries before failing the job (0 = infinite until reset_time).
}

// Rate limit backed by the Gubernator distributed rate limiting service.
// Allows controlling job throughput based on request rates.
message GubernatorRateLimit {
  string name = 1;                        // Human-readable name for debugging and metrics.
  string unique_key = 2;                  // Unique identifier for this rate limit instance (e.g., user ID).
  int64 limit = 3;                        // Maximum number of requests allowed within the duration.
  int64 duration_ms = 4;                  // Time window in milliseconds for the rate limit.
  int32 hits = 5;                         // Number of hits this job consumes (usually 1).
  GubernatorAlgorithm algorithm = 6;      // Algorithm for rate limiting (token bucket or leaky bucket).
  int32 behavior = 7;                     // Behavior flags - combine GubernatorBehavior values with OR.
  RateLimitRetryPolicy retry_policy = 8;  // Policy for retrying when rate limited.
}

// Union type representing any kind of limit that can be applied to a job.
// Jobs can have multiple limits; all must be satisfied before execution.
message Limit {
  oneof limit {
    ConcurrencyLimit concurrency = 1;             // Static concurrency limit.
    GubernatorRateLimit rate_limit = 2;           // Gubernator-based rate limit.
    FloatingConcurrencyLimit floating_concurrency = 3; // Dynamic worker-computed concurrency limit.
  }
}

// Request to enqueue a new job for processing.
message EnqueueRequest {
  string shard = 1;                      // Shard ID (UUID) where the job should be stored.
  string id = 2;                         // Optional job ID. If empty, a random UUID is generated.
  uint32 priority = 3;                   // Priority from 0-99. Lower is higher priority (0 = highest).
  int64 start_at_ms = 4;                 // Unix timestamp (ms) for future scheduling. 0 = run immediately.
  optional RetryPolicy retry_policy = 5; // Retry configuration. If absent, job fails on first error.
  SerializedBytes payload = 6;              // Opaque serialized payload passed to workers.
  repeated Limit limits = 7;             // Ordered list of limits checked before execution.
  optional string tenant = 8;            // Tenant ID for multi-tenant deployments. Optional.
  map<string, string> metadata = 9;      // Arbitrary key/value metadata stored with the job.
  string task_group = 10;                // Task group for organizing tasks. Required. Tasks are enqueued into this group.
}

// Response after successfully enqueueing a job.
message EnqueueResponse {
  string id = 1; // The job's ID (either provided or auto-generated).
}

// Current state of a job in its lifecycle.
enum JobStatus {
  JOB_STATUS_SCHEDULED = 0;  // Job is waiting to be executed (queued or scheduled for future).
  JOB_STATUS_RUNNING = 1;    // Job is currently being processed by a worker.
  JOB_STATUS_SUCCEEDED = 2;  // Job completed successfully.
  JOB_STATUS_FAILED = 3;     // Job failed after exhausting all retry attempts.
  JOB_STATUS_CANCELLED = 4;  // Job was cancelled before completion.
}

// Request to retrieve details about a specific job.
message GetJobRequest {
  string shard = 1;          // Shard ID (UUID) where the job is stored.
  string id = 2;             // The job's unique ID.
  optional string tenant = 3; // Tenant ID if multi-tenancy is enabled.
  bool include_attempts = 4; // If true, include all attempts in the response. Defaults to false.
}

// Status of a job attempt in its lifecycle.
enum AttemptStatus {
  ATTEMPT_STATUS_RUNNING = 0;   // Attempt is currently running.
  ATTEMPT_STATUS_SUCCEEDED = 1; // Attempt completed successfully.
  ATTEMPT_STATUS_FAILED = 2;    // Attempt failed.
  ATTEMPT_STATUS_CANCELLED = 3; // Attempt was cancelled.
}

// A single execution attempt of a job.
message JobAttempt {
  string job_id = 1;                     // The job's unique ID.
  uint32 attempt_number = 2;             // Which attempt this is (1 = first attempt).
  string task_id = 3;                    // Unique task ID for this attempt.
  AttemptStatus status = 4;              // Current status of the attempt.
  int64 started_at_ms = 5;               // Unix timestamp (ms) when attempt started. Present for all attempts.
  optional int64 finished_at_ms = 6;     // Unix timestamp (ms) when attempt finished. Present if completed.
  optional SerializedBytes result = 7;     // Result data if attempt succeeded.
  optional string error_code = 8;          // Error code if attempt failed.
  optional SerializedBytes error_data = 9; // Error details if attempt failed.
}

// Full details of a job including its current state.
message GetJobResponse {
  string id = 1;                         // The job's unique ID.
  uint32 priority = 2;                   // Job priority (0 = highest, 99 = lowest).
  int64 enqueue_time_ms = 3;             // Unix timestamp (ms) when job was enqueued.
  SerializedBytes payload = 4;           // The job's payload data.
  optional RetryPolicy retry_policy = 5; // Retry policy if configured.
  repeated Limit limits = 6;             // Limits declared on this job.
  map<string, string> metadata = 7;      // Metadata key/value pairs.
  JobStatus status = 8;                  // Current job status.
  int64 status_changed_at_ms = 9;        // Unix timestamp (ms) of last status change.
  repeated JobAttempt attempts = 10;     // All attempts for this job. Only populated if include_attempts was true in the request.
  optional int64 next_attempt_starts_after_ms = 11; // Unix timestamp (ms) when the next attempt will start. Present for scheduled jobs, absent for running or terminal jobs.
  string task_group = 12;                // Task group this job's tasks are enqueued into.
}

// Request to get the result of a completed job.
// Only succeeds if the job has reached a terminal state (succeeded, failed, or cancelled).
message GetJobResultRequest {
  string shard = 1;          // Shard ID (UUID) where the job is stored.
  string id = 2;             // The job's unique ID.
  optional string tenant = 3; // Tenant ID if multi-tenancy is enabled.
}

// Result of a completed job. Check status to determine which result field is populated.
message GetJobResultResponse {
  string id = 1;             // The job's unique ID.
  JobStatus status = 2;      // Terminal status: SUCCEEDED, FAILED, or CANCELLED.
  int64 finished_at_ms = 3;  // Unix timestamp (ms) when job reached terminal state.
  
  // The result depends on the terminal status.
  oneof result {
    SerializedBytes success_data = 4;   // Present if status == SUCCEEDED. Contains job result.
    JobFailure failure = 5;          // Present if status == FAILED. Contains error details.
    JobCancelled cancelled = 6;      // Present if status == CANCELLED. Contains cancellation info.
  }
}

// Error information for a failed job.
message JobFailure {
  string error_code = 1;    // Application-defined error code.
  SerializedBytes error_data = 2; // Serialized error details.
}

// Information about a cancelled job.
message JobCancelled {
  int64 cancelled_at_ms = 1; // Unix timestamp (ms) when cancellation was requested.
}

// Request to permanently delete a job and all its data.
message DeleteJobRequest {
  string shard = 1;          // Shard ID (UUID) where the job is stored.
  string id = 2;             // The job's unique ID.
  optional string tenant = 3; // Tenant ID if multi-tenancy is enabled.
}

// Response confirming job deletion.
message DeleteJobResponse {}

// Request to cancel a job. Running jobs will be notified via heartbeat response.
message CancelJobRequest {
  string shard = 1;          // Shard ID (UUID) where the job is stored.
  string id = 2;             // The job's unique ID.
  optional string tenant = 3; // Tenant ID if multi-tenancy is enabled.
}

// Response confirming cancellation was requested.
message CancelJobResponse {}

// Restart a cancelled or failed job, allowing it to be processed again.
// The job will get a fresh set of retries according to its retry policy.
message RestartJobRequest { string shard = 1; string id = 2; optional string tenant = 3; }
message RestartJobResponse {}

// Expedite a future-scheduled job to run immediately.
// This is useful for dragging forward a job that was scheduled for the future,
// or for skipping retry backoff delays on a mid-retry job.
message ExpediteJobRequest { string shard = 1; string id = 2; optional string tenant = 3; }
message ExpediteJobResponse {}

// Lease tasks for processing from this server.
// By default, leases from all shards this server owns (fair distribution).
// If shard is specified, filters to only that shard.
message LeaseTasksRequest { 
  optional string shard = 1;  // optional filter - if set, only lease from this shard (UUID)
  string worker_id = 2; 
  uint32 max_tasks = 3;
  string task_group = 4;      // Required. Task group to poll tasks from.
}

// A task representing a single job attempt leased to a worker.
message Task {
  string id = 1;                      // Unique task ID (different from job ID).
  string job_id = 2;                  // ID of the job this task belongs to.
  optional string tenant_id = 3;      // Tenant ID if multi-tenancy is enabled.
  uint32 attempt_number = 4;          // Which attempt this is (1 = first attempt). Monotonically increasing across restarts.
  uint32 relative_attempt_number = 5; // Attempt within current run (1 = first attempt since last restart). Resets on restart.
  bool is_last_attempt = 6;           // True if this is the final attempt (no more retries after this run).
  map<string, string> metadata = 7;   // Metadata key/value pairs from the job.
  repeated Limit limits = 8;          // Limits declared on this job (concurrency, rate, floating).
  SerializedBytes payload = 9;        // The job's payload for the worker to process.
  uint32 priority = 10;               // Job priority (for informational purposes).
  string shard = 11;                  // Shard ID (UUID) this task came from (needed for reporting outcome).
  string task_group = 12;             // Task group this task belongs to.
  int64 lease_ms = 13;                // How long the lease lasts. Heartbeat before this expires.
}

// Task for refreshing a floating concurrency limit.
// Workers compute the new max_concurrency and report back.
message RefreshFloatingLimitTask {
  string id = 1;                       // Unique task ID for this refresh.
  string queue_key = 2;                // The floating limit key being refreshed.
  uint32 current_max_concurrency = 3;  // Current max concurrency value.
  int64 last_refreshed_at_ms = 4;      // Unix timestamp (ms) of last refresh.
  map<string, string> metadata = 5;    // Metadata from the limit definition.
  int64 lease_ms = 6;                  // How long the lease lasts. Heartbeat before this expires.
  string shard = 7;                    // Shard ID (UUID) this task came from (needed for reporting outcome).
  string task_group = 8;               // Task group this refresh task belongs to.
  optional string tenant_id = 9;       // Tenant ID if multi-tenancy is enabled.
}

// Response containing tasks leased to a worker.
message LeaseTasksResponse {
  repeated Task tasks = 1;                         // Job execution tasks.
  repeated RefreshFloatingLimitTask refresh_tasks = 2; // Floating limit refresh tasks.
}

// Request to report the outcome of a completed task.
// Note: tenant is determined from the task lease, not from the request.
message ReportOutcomeRequest {
  string shard = 1;          // Shard ID (UUID) the task came from.
  string task_id = 2;        // The task's unique ID.
  oneof outcome {
    SerializedBytes success = 3;   // Job succeeded. Contains result data from executing the job.
    Failure failure = 4;        // Job failed. Contains error details.
    Cancelled cancelled = 6;    // Worker acknowledges job was cancelled.
  }
}

// Error details for a failed task.
message Failure {
  string code = 1;           // Application-defined error code.
  SerializedBytes data = 2;  // Serialized error details.
}

// Marker indicating the worker acknowledges the job was cancelled.
message Cancelled {}

// Response confirming outcome was recorded.
message ReportOutcomeResponse {}

// Request to report the outcome of a floating limit refresh task.
// Note: tenant is determined from the task lease, not from the request.
message ReportRefreshOutcomeRequest {
  string shard = 1;          // Shard ID (UUID) the task came from.
  string task_id = 2;        // The task's unique ID.
  oneof outcome {
    RefreshSuccess success = 4; // Refresh succeeded with new max concurrency.
    RefreshFailure failure = 5; // Refresh failed.
  }
}

// Successful floating limit refresh with the new computed value.
message RefreshSuccess {
  uint32 new_max_concurrency = 1; // New max concurrency computed by the worker.
}

// Error during floating limit refresh.
message RefreshFailure {
  string code = 1;    // Error code.
  string message = 2; // Human-readable error message.
}

// Response confirming refresh outcome was recorded.
message ReportRefreshOutcomeResponse {}

// Request to extend a task lease and check for cancellation.
// Workers must heartbeat before lease_ms expires to keep the task.
// Note: tenant is determined from the task lease, not from the request.
message HeartbeatRequest {
  string shard = 1;          // Shard ID (UUID) the task came from.
  string worker_id = 2;      // Worker ID that holds the lease.
  string task_id = 3;        // The task's unique ID.
}

// Response indicating if the lease was extended and if the job was cancelled.
message HeartbeatResponse {
  bool cancelled = 1;               // True if job was cancelled. Worker should stop and report Cancelled.
  optional int64 cancelled_at_ms = 2; // Unix timestamp (ms) when cancellation was requested, if cancelled.
}

// Request to execute an arbitrary SQL query against shard data.
// Useful for ad-hoc inspection and debugging.
message QueryRequest {
  string shard = 1;          // Shard ID (UUID) to query.
  string sql = 2;            // SQL query string.
  optional string tenant = 3; // Tenant ID to scope results, if multi-tenancy is enabled.
}

// Metadata about a column in query results.
message ColumnInfo {
  string name = 1;      // Column name.
  string data_type = 2; // Arrow/DataFusion type as string (e.g., "Utf8", "Int64").
}

// Query results with rows as serialized objects.
message QueryResponse {
  repeated ColumnInfo columns = 1;  // Schema information for the result columns.
  repeated SerializedBytes rows = 2;   // Each row as a serialized object.
  int32 row_count = 3;              // Total number of rows returned.
}

// Request to execute SQL query with Arrow IPC streaming response.
// More efficient than QueryResponse for large result sets.
message QueryArrowRequest {
  string shard = 1;          // Shard ID (UUID) to query.
  string sql = 2;            // SQL query string.
  optional string tenant = 3; // Tenant ID to scope results, if multi-tenancy is enabled.
}

// Arrow IPC encoded message. Part of a streaming response.
message ArrowIpcMessage {
  bytes ipc_data = 1; // Arrow IPC stream data. First message is schema, subsequent are record batches.
}

// Request to get cluster topology for client-side routing.
message GetClusterInfoRequest {}

// Information about which node owns a specific shard.
message ShardOwner {
  string shard_id = 1;  // The shard ID (UUID).
  string grpc_addr = 2; // gRPC address of the node owning this shard.
  string node_id = 3;   // Unique identifier of the owning node.
  string range_start = 4; // Inclusive start of the tenant_id range owned by this shard.
  string range_end = 5;   // Exclusive end of the tenant_id range owned by this shard.
  optional string placement_ring = 6; // Placement ring this shard belongs to (empty = default ring).
}

// Information about a cluster member node.
message ClusterMember {
  string node_id = 1;                   // Unique identifier of this node.
  string grpc_addr = 2;                 // gRPC address of this node.
  repeated string placement_rings = 3;  // Placement rings this node participates in.
}

// Cluster topology information.
message GetClusterInfoResponse {
  uint32 num_shards = 1;                // Total number of shards in the cluster.
  repeated ShardOwner shard_owners = 2; // Mapping of each shard to its owner.
  string this_node_id = 3;              // Node ID of the server responding.
  string this_grpc_addr = 4;            // gRPC address of the server responding.
  repeated ClusterMember members = 5;   // All cluster members with their ring participation.
}

// Request to reset all shards owned by this server.
// WARNING: Destructive operation. Only available in dev mode.
message ResetShardsRequest {}

// Response confirming shards were reset.
message ResetShardsResponse {
  uint32 shards_reset = 1; // Number of shards that were cleared.
}

// Request to capture a CPU profile from this node.
// Used for production debugging and performance analysis.
message CpuProfileRequest {
  uint32 duration_seconds = 1;  // How long to profile (1-300 seconds). Default 30.
  uint32 frequency = 2;         // Sampling frequency in Hz (1-1000). Default 100.
}

// CPU profile data in pprof protobuf format.
// Can be analyzed with `pprof` or `go tool pprof`.
message CpuProfileResponse {
  bytes profile_data = 1;       // pprof protobuf bytes (not gzip compressed).
  uint32 duration_seconds = 2;  // Actual duration profiled.
  uint64 samples = 3;           // Number of samples collected.
}

// Request to initiate a shard split operation.
message RequestSplitRequest {
  string shard_id = 1;     // Shard ID (UUID) of the shard to split.
  string split_point = 2;  // Tenant ID where to split the keyspace.
}

// Response after initiating a shard split.
message RequestSplitResponse {
  string left_child_id = 1;   // UUID of the left child shard [parent_start, split_point).
  string right_child_id = 2;  // UUID of the right child shard [split_point, parent_end).
  string phase = 3;           // Current split phase (e.g., "SplitRequested").
}

// Request to get the status of a shard split operation.
message GetSplitStatusRequest {
  string shard_id = 1;  // Parent shard ID (UUID) of the split operation.
}

// Response with the current split status.
// Returns empty if no split is in progress for the shard.
message GetSplitStatusResponse {
  bool in_progress = 1;        // True if a split is in progress for this shard.
  string phase = 2;            // Current split phase (empty if not in progress).
  string left_child_id = 3;    // UUID of the left child shard (empty if not in progress).
  string right_child_id = 4;   // UUID of the right child shard (empty if not in progress).
  string split_point = 5;      // Tenant ID at which the split occurs (empty if not in progress).
  string initiator_node_id = 6; // Node ID that initiated the split.
  int64 requested_at_ms = 7;   // Unix timestamp (ms) when split was requested.
}

// Information about a shard owned by a node, including counters and cleanup status.
message OwnedShardInfo {
  string shard_id = 1;        // The shard ID (UUID).
  int64 total_jobs = 2;       // Total number of jobs in the shard (not deleted).
  int64 completed_jobs = 3;   // Number of jobs in terminal states (Succeeded, Failed, Cancelled).
  string cleanup_status = 4;  // Cleanup status: "CompactionDone", "CleanupPending", "CleanupRunning", "CleanupDone".
  int64 created_at_ms = 5;    // Unix timestamp (ms) when this shard was first created/initialized.
  int64 cleanup_completed_at_ms = 6; // Unix timestamp (ms) when cleanup completed (0 if not applicable or not completed).
}

// Request to get node information including owned shards with their counters and cleanup status.
message GetNodeInfoRequest {}

// Response with node information and details for all shards owned by this node.
message GetNodeInfoResponse {
  string node_id = 1;                       // Unique identifier of this node.
  repeated OwnedShardInfo owned_shards = 2; // Information for each shard owned by this node.
  repeated string placement_rings = 3;      // Placement rings this node participates in.
}

// Request to configure a shard's placement ring.
message ConfigureShardRequest {
  string shard = 1;                   // The shard ID (UUID) to configure.
  optional string placement_ring = 2; // The placement ring to assign (empty/null = default ring).
  optional string tenant = 100;       // Optional tenant ID (for multi-tenant mode).
}

// Response after configuring a shard's placement ring.
message ConfigureShardResponse {
  string previous_ring = 1; // The placement ring before the change (empty = default ring).
  string current_ring = 2;  // The placement ring after the change (empty = default ring).
}

// A historical attempt record for job import.
// All attempts must be in terminal states (no Running).
message ImportAttempt {
  AttemptStatus status = 1;            // Must be terminal (SUCCEEDED, FAILED, or CANCELLED).
  int64 started_at_ms = 2;            // When the attempt started (epoch ms).
  int64 finished_at_ms = 3;           // When the attempt finished (epoch ms).
  optional SerializedBytes result = 4; // Present if succeeded.
  optional string error_code = 5;      // Present if failed.
  optional SerializedBytes error_data = 6; // Present if failed.
}

// Request to import a single job from another system.
// Unlike Enqueue, ImportJob accepts historical attempts and lets Silo take ownership going forward.
message ImportJobRequest {
  string shard = 1;                      // Shard ID (UUID) where the job should be stored.
  string id = 2;                         // Required job ID (migration preserves IDs).
  uint32 priority = 3;                   // Priority from 0-99. Lower is higher priority.
  int64 enqueue_time_ms = 4;            // Original enqueue time from source system (0 = now).
  int64 start_at_ms = 5;                // When the next attempt should start (0 = now, only for non-terminal).
  optional RetryPolicy retry_policy = 6; // Retry configuration.
  SerializedBytes payload = 7;           // Opaque serialized payload.
  repeated Limit limits = 8;             // Ordered list of limits.
  optional string tenant = 9;            // Tenant ID for multi-tenant deployments.
  map<string, string> metadata = 10;     // Arbitrary key/value metadata.
  string task_group = 11;               // Task group for organizing tasks.
  repeated ImportAttempt attempts = 12;  // Historical attempts, all terminal.
}

// Batch request to import multiple jobs.
message ImportJobsRequest {
  repeated ImportJobRequest jobs = 1;
}

// Result of importing a single job.
message ImportJobResult {
  string id = 1;               // The job's ID.
  bool success = 2;            // Whether the import succeeded.
  optional string error = 3;   // Error message if import failed.
  JobStatus status = 4;        // The determined status of the imported job.
}

// Response containing results for each imported job.
message ImportJobsResponse {
  repeated ImportJobResult results = 1;
}

// The Silo job queue service.
service Silo {
  // Get cluster topology for client-side routing.
  // Returns shard ownership information so clients can route requests to the correct node.
  rpc GetClusterInfo(GetClusterInfoRequest) returns (GetClusterInfoResponse);
  
  // Get information about this node and all the shards it owns.
  rpc GetNodeInfo(GetNodeInfoRequest) returns (GetNodeInfoResponse);

  // Enqueue a new job for processing.
  // The job will be scheduled according to its start_at_ms and processed when limits allow.
  rpc Enqueue(EnqueueRequest) returns (EnqueueResponse);
  
  // Get full details of a job including its current status.
  rpc GetJob(GetJobRequest) returns (GetJobResponse);
  
  // Get the result of a completed job.
  // Returns NOT_FOUND if the job doesn't exist.
  // Returns FAILED_PRECONDITION if the job hasn't reached a terminal state.
  rpc GetJobResult(GetJobResultRequest) returns (GetJobResultResponse);
  
  // Permanently delete a job and all its data.
  // Running jobs should be cancelled first.
  rpc DeleteJob(DeleteJobRequest) returns (DeleteJobResponse);
  
  // Cancel a job. Running jobs will be notified via heartbeat.
  // Jobs in any state can be cancelled.
  rpc CancelJob(CancelJobRequest) returns (CancelJobResponse);
  
  // Restart a cancelled or failed job for another attempt.
  // Returns FAILED_PRECONDITION if job is not in a restartable state.
  // Returns NOT_FOUND if the job doesn't exist.
  rpc RestartJob(RestartJobRequest) returns (RestartJobResponse);
  
  // Expedite a future-scheduled job to run immediately.
  // Useful for dragging forward scheduled jobs or skipping retry backoff delays.
  // Returns FAILED_PRECONDITION if job is not in an expeditable state
  // (already running, terminal, cancelled, or task already ready to run).
  // Returns NOT_FOUND if the job doesn't exist.
  rpc ExpediteJob(ExpediteJobRequest) returns (ExpediteJobResponse);
  
  // Lease tasks for a worker to process.
  // Workers should call this periodically to get work.
  // Returns both job tasks and floating limit refresh tasks.
  rpc LeaseTasks(LeaseTasksRequest) returns (LeaseTasksResponse);
  
  // Report the outcome of a completed job task.
  // Must be called before the task lease expires.
  rpc ReportOutcome(ReportOutcomeRequest) returns (ReportOutcomeResponse);
  
  // Report the outcome of a floating limit refresh task.
  // Workers compute new max_concurrency and report here.
  rpc ReportRefreshOutcome(ReportRefreshOutcomeRequest) returns (ReportRefreshOutcomeResponse);
  
  // Extend a task lease and check for cancellation.
  // Workers must heartbeat before lease expires to keep tasks.
  // Returns cancelled=true if the job was cancelled.
  rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse);
  
  // Execute an SQL query against shard data.
  // Returns results as JSON rows.
  rpc Query(QueryRequest) returns (QueryResponse);
  
  // Execute an SQL query with Arrow IPC streaming response.
  // More efficient for large result sets.
  // First message contains schema, subsequent messages contain record batches.
  rpc QueryArrow(QueryArrowRequest) returns (stream ArrowIpcMessage);
  
  // Capture a CPU profile from this node.
  // Returns pprof protobuf data that can be analyzed with pprof or go tool pprof.
  // The profile captures CPU usage for the specified duration.
  rpc CpuProfile(CpuProfileRequest) returns (CpuProfileResponse);
  
  // Request a shard split operation.
  // Initiates splitting a shard into two child shards at the specified split point.
  // Returns FAILED_PRECONDITION if a split is already in progress.
  // Returns NOT_FOUND if the shard doesn't exist on this node.
  // Returns INVALID_ARGUMENT if the split point is outside the shard's range.
  rpc RequestSplit(RequestSplitRequest) returns (RequestSplitResponse);
  
  // Get the status of a shard split operation.
  // Returns the current phase and child shard IDs if a split is in progress.
  // If no split is in progress, returns with in_progress=false.
  rpc GetSplitStatus(GetSplitStatusRequest) returns (GetSplitStatusResponse);

  // Configure a shard's placement ring.
  // Changes which placement ring the shard belongs to, affecting which nodes can own it.
  // The shard will be handed off to a node that participates in the new ring.
  // Returns the previous and current ring assignments.
  rpc ConfigureShard(ConfigureShardRequest) returns (ConfigureShardResponse);

  // Import jobs from another system with historical attempts.
  // Unlike Enqueue, ImportJobs accepts completed attempt records and lets Silo
  // take ownership going forward. Used for migrating workloads from other job queues.
  // Each job is imported independently; per-job errors are returned in the response.
  rpc ImportJobs(ImportJobsRequest) returns (ImportJobsResponse);

  // Reset all shards owned by this server.
  // WARNING: Destructive operation. Only available in dev mode.
  // Clears all jobs, tasks, queues, and other data.
  rpc ResetShards(ResetShardsRequest) returns (ResetShardsResponse);
}
