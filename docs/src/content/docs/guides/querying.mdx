---
title: Querying Jobs
description: Using SQL to inspect and debug job data
---

import { Aside } from '@astrojs/starlight/components';

Silo includes a SQL query engine powered by [Apache DataFusion](https://datafusion.apache.org/). You can query job data for debugging, inspection, and operational monitoring using `siloctl query` or the gRPC `Query` RPC.

## Basic Usage

Query a single shard with `siloctl`:

```bash
siloctl query 0 "SELECT id, status_kind, task_group FROM jobs LIMIT 10"
```

For JSON output (useful for scripting):

```bash
siloctl --json query 0 "SELECT id, status_kind FROM jobs WHERE status_kind = 'Failed'"
```

## Available Tables

### `jobs`

The primary table containing all job data.

| Column | Type | Nullable | Description |
|--------|------|----------|-------------|
| `shard_id` | `Utf8` | No | UUID of the shard storing this job |
| `tenant` | `Utf8` | No | Tenant identifier |
| `id` | `Utf8` | No | Job ID |
| `priority` | `UInt8` | No | Priority (0 = highest, 99 = lowest) |
| `enqueue_time_ms` | `Int64` | No | Unix timestamp in ms when the job was enqueued |
| `payload` | `Utf8` | Yes | Job payload serialized as JSON |
| `status_kind` | `Utf8` | Yes | Current status: `Scheduled`, `Running`, `Failed`, `Cancelled`, `Succeeded` |
| `status_changed_at_ms` | `Int64` | Yes | Unix timestamp in ms of the last status change |
| `task_group` | `Utf8` | No | Task group the job belongs to |
| `metadata` | `Map<Utf8, Utf8>` | Yes | Arbitrary key-value metadata |

### `queues`

Concurrency queue data showing holders and requesters.

| Column | Type | Nullable | Description |
|--------|------|----------|-------------|
| `shard_id` | `Utf8` | No | UUID of the shard |
| `tenant` | `Utf8` | No | Tenant identifier |
| `queue_name` | `Utf8` | No | Concurrency queue key |
| `entry_type` | `Utf8` | No | `holder` or `requester` |
| `task_id` | `Utf8` | No | Task ID holding or requesting the slot |
| `job_id` | `Utf8` | Yes | Job ID (for requesters) |
| `priority` | `UInt8` | Yes | Priority (for requesters) |
| `timestamp_ms` | `Int64` | No | Grant time (holders) or start time (requesters) |

## Example Queries

**Count jobs by status:**

```sql
SELECT status_kind, COUNT(*) as count
FROM jobs
GROUP BY status_kind
```

**Find failed jobs for a tenant:**

```sql
SELECT id, status_changed_at_ms, task_group
FROM jobs
WHERE tenant = 'customer-123' AND status_kind = 'Failed'
ORDER BY status_changed_at_ms DESC
LIMIT 20
```

**Find jobs by task group:**

```sql
SELECT id, status_kind, priority
FROM jobs
WHERE task_group = 'emails' AND status_kind = 'Scheduled'
```

**Check concurrency queue state:**

```sql
SELECT queue_name, entry_type, COUNT(*) as count
FROM queues
GROUP BY queue_name, entry_type
```

## Metadata Filtering

Job metadata is stored as a `Map<Utf8, Utf8>`. To filter by metadata values, use the `element_at` function:

```sql
SELECT id, status_kind
FROM jobs
WHERE element_at(metadata, 'user_id') = 'user-456'
```

You can combine metadata filters with other conditions:

```sql
SELECT id, status_kind, metadata
FROM jobs
WHERE element_at(metadata, 'environment') = 'production'
  AND status_kind = 'Failed'
LIMIT 50
```

<Aside type="note">
Metadata equality filters on `tenant`, `status_kind`, and `id` are pushed down to the storage scanner for better performance. Other filters are applied after scanning.
</Aside>

## Cluster-Wide Queries

When running in a cluster, use the `ClusterQuery` RPC to query across all shards. The query is fanned out to every shard in parallel, and results are streamed back as Arrow IPC batches.

```bash
# Query all shards through any node
siloctl query --cluster "SELECT status_kind, COUNT(*) as count FROM jobs GROUP BY status_kind"
```

Cluster queries are useful for aggregate views across the entire system. Each shard executes the query independently, and results are merged on the coordinating node.

## Scan Limits

By default, the query scanner reads up to **10,000 rows** per shard. Use a `LIMIT` clause to control how many rows you receive:

```sql
-- Get just the first 5 results
SELECT id, status_kind FROM jobs LIMIT 5

-- The scanner will still read up to 10,000 rows internally
-- Use LIMIT to control the result set size
```

<Aside type="caution">
Queries scan job data from the underlying storage engine. Very large result sets can be slow. Use `WHERE` filters and `LIMIT` clauses to keep queries fast.
</Aside>

## EXPLAIN

Use `EXPLAIN` to debug query plans and understand how filters are being applied:

```bash
siloctl query 0 "EXPLAIN SELECT id FROM jobs WHERE status_kind = 'Failed'"
```

This shows the DataFusion execution plan, including which filters were pushed down to the scanner and which are applied post-scan.
