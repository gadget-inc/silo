- [x] task dequeuing
  - [x] in-memory task broker checks if the task is already leased before brokering it
- [x] task leases, heartbeats
- [x] attempt failure/success reporting
- [x] lease expiry
- [x] deleting a job deletes the tasks for it (should this be a scan or another index?)
- [ ] performance improvement to add attempt view, task view, so we're not deserializing into structs
- [x] GRPC layer for invoking functions
- [ ] limits on payload, error, result size
- [x] cancel api
  - [x] restart cancelled api
- [x] run next attempt now RPC (expedite)
  - [ ] figure out how to avoid having to scan for all future tasks and delete performance issue
- [x] get job info api
- [x] get job with attempts api
- [x] performant, clear storage for job payload, result, and error data
- [x] list jobs api
- [x] job query api
  - [ ] unhappy path tests
  - [ ] limits on resource usage
  - [ ] verify all query patterns needed by gadget are supported and performant
- [x] clustering
  - [x] etcd leasing
  - [x] integration tests of some sort
  - [x] only run one reconcile loop at once
  - [ ] think through if failing open when control plane is down is ok with write fencing
  - [ ] add new coordination mode for persistent disk wal storage and k8s restarts
    - if using persistent disk for the wal, the wal only exists there, and we dont have full compute/storage separation. instead, let's expect any crashed nodes to come back, and rely on cloud provider persistent disk implementations to make that disk available elsewhere. the lease must thusly _not_ expire when a pod goes away, and instead must be explicitly released when it is ready to release it.
  - [ ] figure out how to balance shards, placement engine?
- [ ] floating concurrency limits
  - [x] basics
  - [x] typescript client implementation
  - [ ] failure to refresh handling
  - [ ] performance optimization to not refresh if no jobs currently enqueued with limit
- [ ] review what happened with the check-if-cancelled-on-dequeue thing happened, if alloy model matches rust impl
- [x] webui / operator tooling
  - [ ] use / refine
- [x] /healthz endpoint
- [x] /metrics prometheus endpoint
- [ ] opentelemetry support
- [x] investigate how we might do schema evolution
- [x] secondary indexes for filtering
  - requirements:
    - [x] pagination of some sort
    - [x] optional filter on job id
    - [x] optional filter on job state
    - [x] optional filter on new metadata key/values
    - [x] fancy sql api
- [ ] once transaction support, make enqueue idempotency not a read-then-write but some sort of conditional write
- [ ] validate that concurrency queues can reach 0
- [ ] validate GRPC typescript client retry configuration with toxiproxy
- [ ] waiting state? that matches the gadget ui, but we dont have it modeled because it changes in time without anything else changing
  - [ ] do we need to be able to query for it in the SQL layer? probably
- [ ] worker <=> server GRPC auth
- [ ] much more simulation testing
- [ ] rust best practices review
- [ ] benchmarks in CI, codspeed or similar regression tracker
- [ ] make sure failure data is also stored using msgpack
- [ ] shard splitting
  - [x] wire up re-cleanup on re-aquire
  - [x] add tests for actually processing jobs before cleanup has happened
  - [x] validate all sigils present
  - [x] add split DST scenarios
  - [x] ensure that cleanup is aborted cleanly when a shard is closed mid-cleanup
- [ ] asynchronously hydrate concurrency queue counts to make startup faster
